{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5c61878",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_num = 2\n",
    "folder = f\"D:/Comparison_{q_num}/\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e7c2525",
   "metadata": {},
   "source": [
    "First we build a dataset using the duels_question_1.csv duels, images from Sample_web_green, saved to D:/Comparison_1. Set split is 60% training, 20% validation, 20% testing. (This may take a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6e9e7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving as .npy\n",
      "D:/duels_question_1.csv\n",
      "Creating inputs from csv ...\n",
      "Done\n",
      "Saving test set ...\n",
      "Done\n",
      "Saving train set ...\n",
      "Done\n",
      "Converting to .tfrecords\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from data import *\n",
    "build_dataset(f\"D:/duels_question_{q_num}.csv\", 224, \"D:/Sample_web_green\", folder, 0.2, 0.2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3fa3f768",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53eefdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from Model_comparisons import *\n",
    "dataset_val = tf.data.TFRecordDataset(folder+'data_val.tfrecord')\n",
    "dataset_train = tf.data.TFRecordDataset(folder+'data_train.tfrecord')\n",
    "\n",
    "batch_size = 6\n",
    "\n",
    "dataset_train = dataset_train.map(map_fn)\n",
    "dataset_train = dataset_train.shuffle(2048, reshuffle_each_iteration = True)\n",
    "dataset_train = dataset_train.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "dataset_train = dataset_train.batch(batch_size)\n",
    "\n",
    "dataset_val = dataset_val.map(map_fn)\n",
    "dataset_val = dataset_val.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "dataset_val = dataset_val.batch(batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aaf81b0d",
   "metadata": {},
   "source": [
    "Train a ranking model for 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a0cb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lmacl\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:588: UserWarning: Input dict contained keys ['data_label'] which did not match any model input. They will be ignored by the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477/477 [==============================] - 88s 160ms/step - loss: 0.9917 - accuracy: 0.5084 - val_loss: 0.7376 - val_accuracy: 0.5315\n",
      "Epoch 2/50\n",
      "477/477 [==============================] - 73s 150ms/step - loss: 0.8956 - accuracy: 0.5503 - val_loss: 0.6559 - val_accuracy: 0.6168\n",
      "Epoch 3/50\n",
      "477/477 [==============================] - 73s 151ms/step - loss: 0.8801 - accuracy: 0.5640 - val_loss: 0.6426 - val_accuracy: 0.6573\n",
      "Epoch 4/50\n",
      "477/477 [==============================] - 73s 151ms/step - loss: 0.8340 - accuracy: 0.5930 - val_loss: 0.6539 - val_accuracy: 0.6601\n",
      "Epoch 5/50\n",
      "477/477 [==============================] - 73s 151ms/step - loss: 0.8282 - accuracy: 0.6098 - val_loss: 0.6500 - val_accuracy: 0.6531\n",
      "Epoch 6/50\n",
      "477/477 [==============================] - 75s 154ms/step - loss: 0.7989 - accuracy: 0.6217 - val_loss: 0.6426 - val_accuracy: 0.6601\n",
      "Epoch 7/50\n",
      "477/477 [==============================] - 74s 152ms/step - loss: 0.7963 - accuracy: 0.6308 - val_loss: 0.6233 - val_accuracy: 0.6867\n",
      "Epoch 8/50\n",
      "477/477 [==============================] - 73s 151ms/step - loss: 0.7922 - accuracy: 0.6245 - val_loss: 0.6238 - val_accuracy: 0.6755\n",
      "Epoch 9/50\n",
      "477/477 [==============================] - 73s 151ms/step - loss: 0.7611 - accuracy: 0.6364 - val_loss: 0.5863 - val_accuracy: 0.6979\n",
      "Epoch 10/50\n",
      "477/477 [==============================] - 73s 151ms/step - loss: 0.7482 - accuracy: 0.6360 - val_loss: 0.5874 - val_accuracy: 0.6937\n",
      "Epoch 11/50\n",
      "477/477 [==============================] - 73s 151ms/step - loss: 0.7571 - accuracy: 0.6406 - val_loss: 0.6220 - val_accuracy: 0.6601\n",
      "Epoch 12/50\n",
      "477/477 [==============================] - 73s 151ms/step - loss: 0.7109 - accuracy: 0.6486 - val_loss: 0.6176 - val_accuracy: 0.6741\n",
      "Epoch 13/50\n",
      "477/477 [==============================] - 73s 151ms/step - loss: 0.7422 - accuracy: 0.6455 - val_loss: 0.6423 - val_accuracy: 0.6490\n",
      "Epoch 14/50\n",
      "477/477 [==============================] - 73s 151ms/step - loss: 0.7135 - accuracy: 0.6479 - val_loss: 0.6520 - val_accuracy: 0.6434\n",
      "Epoch 15/50\n",
      "477/477 [==============================] - 74s 152ms/step - loss: 0.7065 - accuracy: 0.6566 - val_loss: 0.5920 - val_accuracy: 0.6881\n",
      "Epoch 16/50\n",
      "133/477 [=======>......................] - ETA: 45s - loss: 0.6739 - accuracy: 0.6779"
     ]
    }
   ],
   "source": [
    "comp_model = comparisons_model(224)\n",
    "#comp_model = load_model(\"D:/acc_checkpoint\") #Or load in from a checkpoint\n",
    "\n",
    "history_comp = comp_model.fit(dataset_train, validation_data = dataset_val, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3a1c51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "vgg = Model(comp_model.layers[5].input, comp_model.layers[5].output)\n",
    "rank_model = ranking_model(224, vgg_feature_extractor = vgg)\n",
    "\n",
    "history_rank = comp_model.fit(dataset_train, validation_data = dataset_val, epochs = 50)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c535622d",
   "metadata": {},
   "source": [
    "plot losses and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09f9ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_comp.history['val_accuracy'], label=\"val_accuracy\")\n",
    "plt.plot(history_comp.history['accuracy'], label=\"accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(folder + \"comp_model_acc.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c2d072",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_comp.history['val_loss'], label=\"val_loss\")\n",
    "plt.plot(history_comp.history['loss'], label=\"loss\")\n",
    "plt.legend()\n",
    "plt.savefig(folder + \"comp_model_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c12ffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_rank.history['val_accuracy'], label=\"val_accuracy\")\n",
    "plt.plot(history_rank.history['accuracy'], label=\"accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(folder + \"rank_model_acc.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7e3e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_rank.history['val_loss'], label=\"val_loss\")\n",
    "plt.plot(history_rank.history['loss'], label=\"loss\")\n",
    "plt.legend()\n",
    "plt.savefig(folder + \"rank_model_loss.png\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83aa68f0",
   "metadata": {},
   "source": [
    "Save model in case it needs to be reused later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2946a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rank_model.save(folder+\"ranking_model.h5\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0893e208",
   "metadata": {},
   "source": [
    "Create Mapillary instance with api access key, and coordinates bounding Ottawa regiong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b0d148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Mapillary import *\n",
    "api = Mapillary('MLY|4459801330748375|f17ddc8a7adbcbff6eea96b1cf4c2aad',\n",
    "                [-75.7839321, 45.3210331], [-75.6517092, 45.4448763]) #Smaller Box around Ottawa\n",
    "              #  [-75.9216253, 45.2157973], [-75.4695785, 45.4958371]) #Big Box around Ottawa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4b1e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "await api.generate_csv(rank_model, folder+\"rankings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "658e40e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from os.path import abspath, join\n",
    "\n",
    "for i in range(1,5):\n",
    "    print(i)\n",
    "    DATA_FOLDER = f\"D:/Comparison_{i}\"\n",
    "    tfrecord = tf.io.TFRecordWriter(join(DATA_FOLDER, \"data_test.tfrecord\"))\n",
    "\n",
    "    data_left = np.load(join(DATA_FOLDER, \"test\", \"test_left_224.npy\"), mmap_mode=None)\n",
    "    data_right = np.load(join(DATA_FOLDER, \"test\", \"test_right_224.npy\"),  mmap_mode=None)\n",
    "    data_label = np.load(join(DATA_FOLDER, \"test\", \"test_labels_224.npy\"), mmap_mode=None)\n",
    "    labels_score = np.load(join(DATA_FOLDER, \"test\", \"test_labels_score_224.npy\"),  mmap_mode=None)\n",
    "    for j in range(data_left.shape[0]): #iterate through all rows\n",
    "        features = {\n",
    "        'data_label' : tf.train.Feature(int64_list=tf.train.Int64List(value=data_label[j])),\n",
    "        'labels_score': tf.train.Feature(int64_list=tf.train.Int64List(value=np.array([labels_score[j]]))),\n",
    "        'data_left': tf.train.Feature(int64_list=tf.train.Int64List(value=data_left[j].astype(int).flatten())),\n",
    "        'data_right': tf.train.Feature(int64_list=tf.train.Int64List(value=data_right[j].astype(int).flatten())),\n",
    "\n",
    "        }\n",
    "\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "        tfrecord.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bc0c26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
